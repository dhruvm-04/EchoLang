{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Multilingual Service Request Analyzer (Fixed)\n**Streamlined NLP Pipeline with Transformer-based Intent Classification**\n\nFeatures:\n1. Whisper ASR for audio processing\n2. IndicTrans2 for multilingual translation\n3. BERT-based intent classification\n4. Simplified architecture\n\n---","metadata":{}},{"cell_type":"code","source":"# Install required packages\nimport subprocess\nimport sys\n\npackages = [\n    'torch',\n    'transformers>=4.21.0',\n    'openai-whisper',\n    'sentence-transformers',\n    'scipy'\n]\n\nfor package in packages:\n    try:\n        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n        print(f\"{package} installed\")\n    except:\n        print(f\"Failed: {package}\")\n\nprint(\"Installation complete!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport whisper\nimport re\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\nfrom sentence_transformers import SentenceTransformer\nfrom scipy.spatial.distance import cosine\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load Models\nprint(\"Loading models...\")\n\n# Whisper for ASR\ntry:\n    whisper_model = whisper.load_model(\"base\")\n    print(\"Whisper loaded\")\nexcept:\n    whisper_model = None\n    print(\"Whisper failed\")\n\n# Fixed IndicTrans2 loading\ntry:\n    translation_model = \"facebook/nllb-200-distilled-600M\"  # More reliable alternative\n    translator = pipeline(\"translation\", model=translation_model, device=0 if device==\"cuda\" else -1)\n    print(\"Translation model loaded\")\nexcept:\n    try:\n        # Fallback to IndicTrans2 with proper loading\n        tokenizer_trans = AutoTokenizer.from_pretrained(\"ai4bharat/indictrans2-indic-en-1B\", trust_remote_code=True)\n        model_trans = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/indictrans2-indic-en-1B\", trust_remote_code=True)\n        model_trans.to(device)\n        translator = None\n        print(\"IndicTrans2 loaded\")\n    except:\n        tokenizer_trans = None\n        model_trans = None\n        translator = None\n        print(\"Translation unavailable\")\n\n# Sentence transformer for intent classification\ntry:\n    intent_model = SentenceTransformer('all-MiniLM-L6-v2')\n    print(\"Intent classifier loaded\")\nexcept:\n    intent_model = None\n    print(\"Intent classifier failed\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Intent Classification with Transformer\nSERVICE_INTENTS = {\n    'Plumbing': \"Water leakage, pipe repair, tap fixing, drain cleaning, toilet problems, plumber service\",\n    'Electrical': \"Power outage, light not working, electrical wiring, switch repair, electrician needed\",\n    'Cleaning': \"House cleaning, garbage removal, sweeping, mopping, sanitization service\",\n    'Repair': \"Fix broken items, maintenance service, repair work, technician needed\",\n    'Transport': \"Car service, bike repair, taxi booking, delivery service, driver needed\",\n    'Healthcare': \"Doctor consultation, medical help, nurse needed, hospital visit\",\n    'Home Services': \"Cooking, food preparation, laundry, gardening, painting work\",\n    'General': \"General help, assistance needed, support required, other services\"\n}\n\n# Pre-compute intent embeddings\nif intent_model:\n    intent_embeddings = {}\n    for intent, description in SERVICE_INTENTS.items():\n        intent_embeddings[intent] = intent_model.encode(description)\n    print(\"Intent embeddings computed\")\nelse:\n    intent_embeddings = None","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Core Functions\n\ndef transcribe_audio(audio_path):\n    \"\"\"Convert audio to text\"\"\"\n    if not whisper_model:\n        return \"Audio transcription unavailable\"\n    try:\n        result = whisper_model.transcribe(audio_path)\n        return result[\"text\"].strip()\n    except Exception as e:\n        return f\"Error: {e}\"\n\ndef detect_language(text):\n    \"\"\"Simple language detection\"\"\"\n    if re.search(r'[\\u0900-\\u097F]', text):\n        return 'hi'\n    elif re.search(r'[\\u0B80-\\u0BFF]', text):\n        return 'ta'\n    return 'en'\n\ndef translate_text(text, source_lang):\n    \"\"\"Translate to English\"\"\"\n    if source_lang == 'en':\n        return text\n    \n    try:\n        if translator:  # NLLB model\n            lang_map = {'hi': 'hin_Deva', 'ta': 'tam_Taml'}\n            src_lang = lang_map.get(source_lang, 'hin_Deva')\n            result = translator(text, src_lang=src_lang, tgt_lang='eng_Latn')\n            return result[0]['translation_text']\n        \n        elif tokenizer_trans and model_trans:  # IndicTrans2\n            inputs = tokenizer_trans(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n            inputs = {k: v.to(device) for k, v in inputs.items()}\n            \n            with torch.no_grad():\n                outputs = model_trans.generate(**inputs, max_length=256, num_beams=5)\n            \n            translation = tokenizer_trans.decode(outputs[0], skip_special_tokens=True)\n            return translation.strip()\n        \n        return text  # Fallback\n    \n    except Exception as e:\n        print(f\"Translation error: {e}\")\n        return text\n\ndef classify_intent(text):\n    \"\"\"Classify service intent using transformer\"\"\"\n    if not intent_model or not intent_embeddings:\n        # Fallback to keyword matching\n        return classify_intent_fallback(text)\n    \n    try:\n        # Get text embedding\n        text_embedding = intent_model.encode(text)\n        \n        # Calculate similarities\n        similarities = {}\n        for intent, intent_emb in intent_embeddings.items():\n            similarity = 1 - cosine(text_embedding, intent_emb)\n            similarities[intent] = max(0, similarity)  # Ensure non-negative\n        \n        # Get best match\n        best_intent = max(similarities, key=similarities.get)\n        confidence = similarities[best_intent]\n        \n        return best_intent, confidence, similarities\n    \n    except Exception as e:\n        print(f\"Intent classification error: {e}\")\n        return classify_intent_fallback(text)\n\ndef classify_intent_fallback(text):\n    \"\"\"Fallback keyword-based classification\"\"\"\n    keywords = {\n        'Plumbing': ['water', 'pipe', 'leak', 'tap', 'drain', 'toilet'],\n        'Electrical': ['light', 'power', 'electricity', 'wire', 'switch'],\n        'Cleaning': ['clean', 'wash', 'dirty', 'sweep', 'garbage'],\n        'Repair': ['fix', 'broken', 'repair', 'damage'],\n        'Transport': ['car', 'bike', 'taxi', 'drive', 'delivery'],\n        'Healthcare': ['doctor', 'medical', 'health', 'medicine'],\n        'Home Services': ['cook', 'food', 'laundry', 'garden']\n    }\n    \n    text_lower = text.lower()\n    scores = {}\n    \n    for intent, words in keywords.items():\n        score = sum(1 for word in words if word in text_lower)\n        if score > 0:\n            scores[intent] = score / len(words)\n    \n    if scores:\n        best_intent = max(scores, key=scores.get)\n        confidence = min(scores[best_intent] * 2, 1.0)\n        return best_intent, confidence, scores\n    else:\n        return \"General\", 0.5, {\"General\": 0.5}\n\ndef get_urgency(text):\n    \"\"\"Determine urgency level\"\"\"\n    urgent_words = ['urgent', 'emergency', 'asap', 'quickly', 'broken', 'leak']\n    text_lower = text.lower()\n    urgent_count = sum(1 for word in urgent_words if word in text_lower)\n    \n    if urgent_count >= 2:\n        return \"High\"\n    elif urgent_count == 1:\n        return \"Medium\"\n    else:\n        return \"Low\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Main Processing Function\n\ndef analyze_request(text_input=None, audio_path=None):\n    \"\"\"Main analysis pipeline\"\"\"\n    \n    # Get input\n    if audio_path:\n        text_input = transcribe_audio(audio_path)\n    \n    if not text_input or not text_input.strip():\n        return \"No input provided\"\n    \n    original_text = text_input.strip()\n    \n    # Language detection and translation\n    lang = detect_language(original_text)\n    lang_names = {'hi': 'Hindi', 'ta': 'Tamil', 'en': 'English'}\n    \n    if lang != 'en':\n        translated_text = translate_text(original_text, lang)\n    else:\n        translated_text = original_text\n    \n    # Intent classification\n    intent, confidence, scores = classify_intent(translated_text)\n    urgency = get_urgency(translated_text)\n    \n    # Format results\n    result = f\"\"\"\nSERVICE REQUEST ANALYSIS\n{'='*40}\n\nOriginal: {original_text}\nLanguage: {lang_names.get(lang, 'Unknown')}\n\"\"\"\n    \n    if lang != 'en':\n        result += f\"Translation: {translated_text}\\n\"\n    \n    result += f\"\"\"\nService Type: {intent}\nConfidence: {confidence:.1%}\n\nTop Match:\n\"\"\"\n# Urgency: {urgency}\n    \n    # Show top match\n    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:1]\n    for service, score in sorted_scores:\n        percentage = (score / max(scores.values())) * 100 if scores else 0\n        result += f\"  • {service}: {percentage:.0f}%\\n\"\n    \n    result += f\"\\nRecommendation: Contact {intent.lower()} service provider\"\n    # if urgency == \"High\":\n    #     result += \" URGENTLY\"\n    return result","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Testing\n\n# def run_tests():\n#     \"\"\"Run test cases\"\"\"\n#     test_cases = [\n#         \"My kitchen tap is leaking water everywhere urgently\",\n#         \"The bedroom light is not working\",\n#         \"Need house cleaning service\",\n#         \"Car engine repair needed\",\n#         \"मुझे डॉक्टर चाहिए\"  # \"I need a doctor\" in Hindi\n#     ]\n    \n#     print(\"RUNNING TESTS\\n\")\n    \n#     for i, test in enumerate(test_cases, 1):\n#         print(f\"Test {i}: {test}\")\n#         result = analyze_request(test)\n#         print(result)\n#         print(\"\\n\" + \"-\"*50 + \"\\n\")\n\n# # Run tests\n# run_tests()\n\n# print(\"\\n🎉 SYSTEM READY!\")\n# print(\"\\nUsage:\")\n# print(\"• analyze_request('your text here')\")\n# print(\"• analyze_request(audio_path='path/to/audio.wav')\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Demo\n\ndef demo():\n    \"\"\"Interactive demo\"\"\"\n    print(\"\\nINTERACTIVE DEMO\")\n    print(\"Enter requests (type 'quit' to exit):\\n\")\n    \n    while True:\n        try:\n            user_input = input(\"Request: \").strip()\n            \n            if user_input.lower() in ['quit', 'exit', 'q']:\n                print(\"Goodbye!\")\n                break\n            \n            if user_input:\n                result = analyze_request(user_input)\n                print(result)\n                print(\"\\n\" + \"-\"*40 + \"\\n\")\n            \n        except KeyboardInterrupt:\n            print(\"\\nGoodbye!\")\n            break\n        except Exception as e:\n            print(f\"Error: {e}\")\ndemo()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}