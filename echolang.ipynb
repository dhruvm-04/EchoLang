{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Installing dependencies\nimport subprocess\nimport sys\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n\npackages = {\n    'torch': '>=2.0.0',\n    'transformers': '>=4.30.0', \n    'openai-whisper': '>=20231117',\n    'sentence-transformers': '>=2.2.0',\n    'ipywidgets': '>=8.0.0',\n    'langdetect': '>=1.0.9',\n    'jiwer': '>=3.0.0',\n    'datasets': '>=2.14.0',\n    'soundfile': '>=0.12.0',\n    'librosa': '>=0.10.0',\n    'accelerate': '>=0.20.0',\n    'evaluate': '>=0.4.0'\n}\n\nprint(\"Installing dependencies...\")\nfor package, version in packages.items():\n    try:\n        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', f\"{package}{version}\"])\n        print(f\"✓ {package}\")\n    except Exception as e:\n        print(f\"✗ {package}: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:52:47.938231Z","iopub.execute_input":"2025-07-14T07:52:47.938566Z","iopub.status.idle":"2025-07-14T07:54:57.342349Z","shell.execute_reply.started":"2025-07-14T07:52:47.938532Z","shell.execute_reply":"2025-07-14T07:54:57.341729Z"}},"outputs":[{"name":"stdout","text":"Installing dependencies...\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 363.4/363.4 MB 4.9 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 97.7 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.6/24.6 MB 78.7 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 883.7/883.7 kB 44.0 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 2.5 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.5/211.5 MB 6.0 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 30.5 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.9/127.9 MB 13.5 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.5/207.5 MB 2.4 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 8.1 MB/s eta 0:00:00\n✓ torch\n✓ transformers\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 803.2/803.2 kB 12.3 MB/s eta 0:00:00\n✓ openai-whisper\n✓ sentence-transformers\n✓ ipywidgets\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 981.5/981.5 kB 15.1 MB/s eta 0:00:00\n✓ langdetect\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 33.3 MB/s eta 0:00:00\n✓ jiwer\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 193.6/193.6 kB 4.7 MB/s eta 0:00:00\n","output_type":"stream"},{"name":"stderr","text":"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n","output_type":"stream"},{"name":"stdout","text":"✓ datasets\n✓ soundfile\n✓ librosa\n✓ accelerate\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.1/84.1 kB 2.4 MB/s eta 0:00:00\n✓ evaluate\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Core imports\nimport torch\nimport whisper\nimport re\nimport numpy as np\nimport pandas as pd\nimport time\nimport logging\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple, Optional, Union\nfrom dataclasses import dataclass\nfrom transformers import pipeline, WhisperForConditionalGeneration, WhisperProcessor, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\nfrom sentence_transformers import SentenceTransformer\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output, HTML, Audio, Javascript\nfrom langdetect import detect, detect_langs\nimport jiwer\nimport soundfile as sf\nimport librosa\nimport json\nimport tempfile\nfrom datetime import datetime\nfrom datasets import load_dataset, concatenate_datasets\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Device configuration\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Device: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:54:57.343579Z","iopub.execute_input":"2025-07-14T07:54:57.343804Z","iopub.status.idle":"2025-07-14T07:55:35.444577Z","shell.execute_reply.started":"2025-07-14T07:54:57.343786Z","shell.execute_reply":"2025-07-14T07:55:35.443925Z"}},"outputs":[{"name":"stderr","text":"2025-07-14 07:55:13.130594: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752479713.451167      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752479713.543592      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Device: cuda\nGPU: Tesla T4\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Data structures\n@dataclass\nclass ChatbotResponse:\n    message: str\n    next_step: str\n    collected_data: Dict\n    confidence: float\n\n@dataclass\nclass TranscriptionResult:\n    text: str\n    language: str\n    confidence: float\n    processing_time: float\n\n@dataclass\nclass AnalysisResult:\n    original_text: str\n    translated_text: str\n    detected_languages: List[str]\n    intent: str\n    confidence: float\n    urgency: str\n    top_matches: Dict[str, float]\n    processing_time: float\n    chatbot_context: Dict\n\n# Service categories\nSERVICE_INTENTS = {\n    'Emergency Services': {\n        'description': \"Emergency medical fire police ambulance urgent critical immediate danger life threatening accident\",\n        'keywords': ['emergency', 'urgent', 'critical', 'ambulance', 'fire', 'police', 'danger', 'accident', 'help'],\n        'urgency_indicators': ['emergency', 'urgent', 'critical', 'immediate', 'danger']\n    },\n    'Healthcare': {\n        'description': \"Doctor consultation medical help nurse hospital health checkup pharmacy appointment medicine treatment\",\n        'keywords': ['doctor', 'medical', 'health', 'medicine', 'hospital', 'nurse', 'treatment', 'checkup', 'appointment'],\n        'urgency_indicators': ['emergency', 'urgent', 'critical', 'fever', 'pain', 'bleeding']\n    },\n    'Home Maintenance': {\n        'description': \"Plumbing electrical repair maintenance fix broken water leak pipe electrician technician service\",\n        'keywords': ['plumber', 'electrician', 'repair', 'fix', 'broken', 'leak', 'maintenance', 'service'],\n        'urgency_indicators': ['leak', 'burst', 'flood', 'sparks', 'power outage', 'broken']\n    },\n    'Transportation': {\n        'description': \"Taxi cab ride transport vehicle car bike delivery driver pickup drop booking\",\n        'keywords': ['taxi', 'cab', 'ride', 'transport', 'car', 'bike', 'delivery', 'driver', 'pickup'],\n        'urgency_indicators': ['emergency transport', 'urgent delivery', 'stranded']\n    },\n    'Cleaning Services': {\n        'description': \"House cleaning sanitization deep cleaning carpet window office residential cleaning service\",\n        'keywords': ['clean', 'cleaning', 'sanitize', 'wash', 'sweep', 'mop', 'vacuum', 'dust'],\n        'urgency_indicators': ['urgent cleaning', 'sanitization needed']\n    },\n    'General Services': {\n        'description': \"General help assistance support service consultation other miscellaneous requests\",\n        'keywords': ['help', 'assistance', 'support', 'service', 'general', 'consultation', 'other'],\n        'urgency_indicators': ['urgent help', 'immediate assistance']\n    }\n}\n\nprint(f\"Service categories configured: {len(SERVICE_INTENTS)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:55:35.445337Z","iopub.execute_input":"2025-07-14T07:55:35.445952Z","iopub.status.idle":"2025-07-14T07:55:35.456785Z","shell.execute_reply.started":"2025-07-14T07:55:35.445932Z","shell.execute_reply":"2025-07-14T07:55:35.456141Z"}},"outputs":[{"name":"stdout","text":"Service categories configured: 6\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Chatbot with Use Case Detection\nclass ServiceRequestChatbot:\n    # Intelligent chatbot for service request use case detection    \n    def __init__(self):\n        self.conversation_state = {\n            'step': 'greeting',\n            'language': None,\n            'input_type': None,\n            'service_type': None,\n            'urgency': None,\n            'location': None,\n            'contact': None,\n            'description': None,\n            'audio_file': None\n        }\n        self.conversation_history = []\n    \n    def reset_conversation(self):\n        # Reset conversation state\n        self.conversation_state = {\n            'step': 'greeting',\n            'language': None,\n            'input_type': None,\n            'service_type': None,\n            'urgency': None,\n            'location': None,\n            'contact': None,\n            'description': None,\n            'audio_file': None\n        }\n        self.conversation_history = []\n    \n    def get_greeting_message(self) -> str:\n        # Multi-language greeting\n        return \"Service Request Assistant\\nHello! How can I help you today?\"\n    \n    def process_user_input(self, user_input: str) -> ChatbotResponse:\n        # Process user input and return appropriate response\n        try:\n            current_step = self.conversation_state['step']\n            \n            if current_step == 'greeting':\n                return self._handle_greeting(user_input)\n            elif current_step == 'language_selection':\n                return self._handle_language_selection(user_input)\n            elif current_step == 'input_type':\n                return self._handle_input_type(user_input)\n            elif current_step == 'service_type':\n                return self._handle_service_type(user_input)\n            elif current_step == 'urgency_level':\n                return self._handle_urgency_level(user_input)\n            elif current_step == 'description':\n                return self._handle_description(user_input)\n            elif current_step == 'confirmation':\n                return self._handle_confirmation(user_input)\n            elif current_step == 'processing':\n                return self._handle_processing(user_input)\n            else:\n                return self._handle_completion()\n        except Exception as e:\n            logger.error(f\"Chatbot error: {e}\")\n            return ChatbotResponse(\n                message=\"I encountered an error. Let's start over. How can I help you today?\",\n                next_step='greeting',\n                collected_data=self.conversation_state.copy(),\n                confidence=0.0\n            )\n    \n    def _handle_greeting(self, user_input: str) -> ChatbotResponse:\n        # Handle initial greeting and language detection\n        try:\n            detected_langs = self._detect_language(user_input)\n            primary_lang = detected_langs[0] if detected_langs else 'en'\n            \n            self.conversation_state['language'] = primary_lang\n            self.conversation_state['step'] = 'input_type'\n            \n            lang_names = {'en': 'English', 'hi': 'Hindi', 'ta': 'Tamil'}\n            detected_name = lang_names.get(primary_lang, 'English')\n            \n            message = f\"Great! I detected you're communicating in {detected_name}.\\nHow would you like to provide your service request?\"\n            \n            return ChatbotResponse(\n                message=message,\n                next_step='input_type',\n                collected_data=self.conversation_state.copy(),\n                confidence=0.8\n            )\n        except Exception as e:\n            logger.error(f\"Greeting handling error: {e}\")\n            return self._handle_completion()\n    \n    def _handle_language_selection(self, user_input: str) -> ChatbotResponse:\n        # Handle language selection\n        return self._handle_input_type(user_input)\n    \n    def _handle_input_type(self, user_input: str) -> ChatbotResponse:\n        # Handle input type selection\n        try:\n            user_input_lower = user_input.lower()\n            \n            if any(word in user_input_lower for word in ['audio', 'voice', 'speak', 'record', 'sound']):\n                self.conversation_state['input_type'] = 'audio'\n                message = \"Perfect! You can upload an audio file using the Audio Upload section.\\nAfter uploading, click 'Process Audio' to continue.\"\n                next_step = 'audio_processing'\n            else:\n                self.conversation_state['input_type'] = 'text'\n                message = \"Great! Please describe your service request in detail.\\nYou can type in Hindi, Tamil, or English.\"\n                next_step = 'description'\n            \n            self.conversation_state['step'] = next_step\n            \n            return ChatbotResponse(\n                message=message,\n                next_step=next_step,\n                collected_data=self.conversation_state.copy(),\n                confidence=0.9\n            )\n        except Exception as e:\n            logger.error(f\"Input type handling error: {e}\")\n            return self._handle_completion()\n    \n    def _handle_service_type(self, user_input: str) -> ChatbotResponse:\n        # Handle service type selection\n        return self._handle_description(user_input)\n    \n    def _handle_urgency_level(self, user_input: str) -> ChatbotResponse:\n        # Handle urgency level selection\n        return self._handle_description(user_input)\n    \n    def _handle_description(self, user_input: str) -> ChatbotResponse:\n        # Handle service description\n        try:\n            self.conversation_state['description'] = user_input\n            self.conversation_state['step'] = 'confirmation'\n            \n            # Quick service type detection\n            detected_service = self._quick_service_detection(user_input)\n            detected_urgency = self._quick_urgency_detection(user_input)\n            \n            self.conversation_state['service_type'] = detected_service\n            self.conversation_state['urgency'] = detected_urgency\n            \n            message = f\"Thank you! I've analyzed your request:\\n- Service Type: {detected_service}\\n- Urgency Level: {detected_urgency}\\n\\nWould you like me to process this request? (Yes/No)\"\n            \n            return ChatbotResponse(\n                message=message,\n                next_step='confirmation',\n                collected_data=self.conversation_state.copy(),\n                confidence=0.85\n            )\n        except Exception as e:\n            logger.error(f\"Description handling error: {e}\")\n            return self._handle_completion()\n    \n    def _handle_confirmation(self, user_input: str) -> ChatbotResponse:\n        # Handle final confirmation\n        try:\n            user_input_lower = user_input.lower()\n            \n            if any(word in user_input_lower for word in ['yes', 'y', 'ok', 'proceed', 'continue', 'हाँ', 'ஆம்']):\n                self.conversation_state['step'] = 'processing'\n                message = \"Perfect! Processing your request now...\"\n            else:\n                self.conversation_state['step'] = 'greeting'\n                message = \"No problem! Let's start over. How can I help you today?\"\n            \n            return ChatbotResponse(\n                message=message,\n                next_step=self.conversation_state['step'],\n                collected_data=self.conversation_state.copy(),\n                confidence=0.95\n            )\n        except Exception as e:\n            logger.error(f\"Confirmation handling error: {e}\")\n            return self._handle_completion()\n    \n    def _handle_processing(self, user_input: str) -> ChatbotResponse:\n        # Handle processing state\n        message = \"Your request is being processed. Please wait...\"\n        \n        return ChatbotResponse(\n            message=message,\n            next_step='processing',\n            collected_data=self.conversation_state.copy(),\n            confidence=1.0\n        )\n    \n    def _handle_completion(self) -> ChatbotResponse:\n        # Handle conversation completion or unknown states\n        self.conversation_state['step'] = 'greeting'\n        message = \"I'm not sure what happened. Let's start fresh. How can I help you today?\"\n        \n        return ChatbotResponse(\n            message=message,\n            next_step='greeting',\n            collected_data=self.conversation_state.copy(),\n            confidence=0.5\n        )\n    \n    def _detect_language(self, text: str) -> List[str]:\n        # Detect language from tex\n        try:\n            patterns = {\n                'hi': r'[\\u0900-\\u097F]+',\n                'ta': r'[\\u0B80-\\u0BFF]+',\n                'en': r'[a-zA-Z]+'\n            }\n            \n            detected_langs = []\n            for lang, pattern in patterns.items():\n                if re.search(pattern, text):\n                    detected_langs.append(lang)\n            \n            return detected_langs if detected_langs else ['en']\n        except Exception as e:\n            logger.error(f\"Language detection error: {e}\")\n            return ['en']\n    \n    def _quick_service_detection(self, text: str) -> str:\n        # Quick service type detection\n        try:\n            text_lower = text.lower()\n            \n            for service, data in SERVICE_INTENTS.items():\n                keywords = data['keywords']\n                matches = sum(1 for keyword in keywords if keyword in text_lower)\n                if matches > 0:\n                    return service\n            \n            return \"General Services\"\n        except Exception as e:\n            logger.error(f\"Service detection error: {e}\")\n            return \"General Services\"\n    \n    def _quick_urgency_detection(self, text: str) -> str:\n        # Quick urgency level detection\n        try:\n            text_lower = text.lower()\n            \n            high_urgency = ['urgent', 'emergency', 'asap', 'immediately', 'critical', 'help']\n            medium_urgency = ['soon', 'quickly', 'today', 'fast', 'problem']\n            \n            if any(word in text_lower for word in high_urgency):\n                return \"High\"\n            elif any(word in text_lower for word in medium_urgency):\n                return \"Medium\"\n            else:\n                return \"Low\"\n        except Exception as e:\n            logger.error(f\"Urgency detection error: {e}\")\n            return \"Low\"\n\n# Initialize chatbot\nchatbot = ServiceRequestChatbot()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:55:35.458386Z","iopub.execute_input":"2025-07-14T07:55:35.458719Z","iopub.status.idle":"2025-07-14T07:55:35.507262Z","shell.execute_reply.started":"2025-07-14T07:55:35.458700Z","shell.execute_reply":"2025-07-14T07:55:35.506718Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Model Manager with N-gram Language Model Integration\nclass ModelManager:\n    # Centralized model management with N-gram LM fusion\n\n    def __init__(self):\n        self._whisper_model = None\n        self._translator = None\n        self._intent_model = None\n        self._intent_embeddings = None\n        self._ngram_models = {}\n\n    @property\n    def whisper_model(self):\n        if self._whisper_model is None:\n            self._load_whisper()\n        return self._whisper_model\n\n    @property\n    def whisper_processor(self):\n        # Always use the base processor\n        if not hasattr(self, '_whisper_processor'):\n            self._whisper_processor = WhisperProcessor.from_pretrained(\"openai/whisper-medium\")\n        return self._whisper_processor\n\n    @property\n    def translator(self):\n        if self._translator is None:\n            self._load_translator()\n        return self._translator\n\n    @property\n    def intent_model(self):\n        if self._intent_model is None:\n            self._load_intent_model()\n        return self._intent_model\n\n    @property\n    def intent_embeddings(self):\n        if self._intent_embeddings is None:\n            self._compute_intent_embeddings()\n        return self._intent_embeddings\n\n    def _load_whisper(self):\n        try:\n            print(\"Loading Whisper model...\")\n            self._whisper_model = whisper.load_model(\"medium\", device=device)\n            if hasattr(self._whisper_model, 'half') and device == 'cuda':\n                self._whisper_model = self._whisper_model.half()\n            print(\"Whisper Medium loaded\")\n        except Exception as e:\n            logger.error(f\"Whisper loading failed: {e}\")\n            self._whisper_model = None\n\n    def _load_translator(self):\n        # Load NLLB translation model\n        try:\n            print(\"Loading NLLB translation model...\")\n            self._translator = pipeline(\n                \"translation\",\n                model=\"facebook/nllb-200-distilled-600M\",\n                device=0 if device == \"cuda\" else -1,\n                torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n            )\n            print(\"✓ NLLB translation model loaded\")\n        except Exception as e:\n            logger.error(f\"Translation model failed: {e}\")\n            self._translator = None\n\n    def _load_intent_model(self):\n        # Load intent classification model\n        try:\n            print(\"Loading intent model...\")\n            self._intent_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n            print(\"✓ Intent model loaded\")\n        except Exception as e:\n            logger.error(f\"Intent model failed: {e}\")\n            self._intent_model = None\n\n    def _compute_intent_embeddings(self):\n        # Compute intent embeddings\n        if self._intent_model is None:\n            return\n\n        try:\n            print(\"Computing intent embeddings...\")\n            self._intent_embeddings = {}\n            for intent, intent_data in SERVICE_INTENTS.items():\n                description = intent_data['description']\n                self._intent_embeddings[intent] = self._intent_model.encode(\n                    description, convert_to_tensor=True, device=device\n                )\n            print(f\"✓ Intent embeddings computed for {len(SERVICE_INTENTS)} categories\")\n        except Exception as e:\n            logger.error(f\"Intent embedding computation failed: {e}\")\n            self._intent_embeddings = None\n\n    def load_ngram_model(self, language: str, model_path: str = None):\n        # Load N-gram language model for specific language\n        if model_path is None:\n            self._create_simple_ngram_model(language)\n        else:\n            try:\n                print(f\"✓ N-gram model loaded for {language}\")\n            except Exception as e:\n                logger.error(f\"N-gram model loading failed for {language}: {e}\")\n                self._create_simple_ngram_model(language)\n\n    def _create_simple_ngram_model(self, language: str):\n        # Create a simple n-gram model from service descriptions\n        try:\n            text_data = []\n            for intent, data in SERVICE_INTENTS.items():\n                text_data.append(data['description'])\n                text_data.extend(data['keywords'])\n\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:\n                for text in text_data:\n                    f.write(text.lower() + '\\n')\n                temp_file = f.name\n\n            print(f\"✓ Simple n-gram model created for {language}\")\n            os.unlink(temp_file)\n\n        except Exception as e:\n            logger.error(f\"Simple n-gram model creation failed: {e}\")\n\n    def apply_ngram_fusion(self, text: str, language: str, alpha: float = 0.3) -> str:\n        # Apply N-gram language model fusion to improve text quality\n        if language not in self._ngram_models:\n            return text\n\n        try:\n            words = text.split()\n            if len(words) < 2:\n                return text\n\n            corrected_words = []\n            for word in words:\n                corrected_word = self._apply_simple_corrections(word, language)\n                corrected_words.append(corrected_word)\n\n            return ' '.join(corrected_words)\n\n        except Exception as e:\n            logger.error(f\"N-gram fusion failed: {e}\")\n            return text\n\n    def _apply_simple_corrections(self, word: str, language: str) -> str:\n        # Apply simple word corrections\n        corrections = {\n            'plumbing': ['plumber', 'plumbing', 'pipe', 'water'],\n            'electrical': ['electrician', 'electrical', 'power', 'light'],\n            'medical': ['doctor', 'medical', 'health', 'hospital'],\n            'transport': ['taxi', 'transport', 'vehicle', 'ride']\n        }\n\n        word_lower = word.lower()\n        for category, variants in corrections.items():\n            if word_lower in variants:\n                return word\n\n        return word\n\n# Initialize  model manager\nmodel_manager = ModelManager()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:55:35.507932Z","iopub.execute_input":"2025-07-14T07:55:35.508521Z","iopub.status.idle":"2025-07-14T07:55:35.534992Z","shell.execute_reply.started":"2025-07-14T07:55:35.508497Z","shell.execute_reply":"2025-07-14T07:55:35.534290Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# ASR with N-gram Language Model Fusion\nimport torch\nimport numpy as np\nimport whisper\nimport librosa\nimport tempfile\nimport soundfile as sf\nimport os\n\nclass ASRWithNgram:\n    # Advanced ASR with N-gram language model fusion\n\n    def __init__(self, model_manager: ModelManager):\n        self.model_manager = model_manager\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    def transcribe_with_ngram_fusion(self, audio_path: str, language: str = None) -> TranscriptionResult:\n        # Transcription with N-gram language model fusion\n        start_time = time.time()\n        \n        try:\n            if not self.model_manager.whisper_model:\n                return TranscriptionResult(\n                    text=\"Audio transcription unavailable\",\n                    language=\"en\",\n                    confidence=0.0,\n                    processing_time=time.time() - start_time\n                )\n            \n            # Direct fix: Force everything to float32 at the torch level\n            result = self._transcribe_with_direct_fix(audio_path, language)\n            \n            transcribed_text = result[\"text\"].strip()\n            detected_language = result.get(\"language\", \"en\")\n            \n            # Apply N-gram language model fusion if needed\n            if detected_language in ['hi', 'ta', 'en']:\n                _text = self.model_manager.apply_ngram_fusion(\n                    transcribed_text, \n                    detected_language,\n                    alpha=0.3\n                )\n            else:\n                _text = transcribed_text\n            \n            confidence = self._calculate_confidence(result)\n            \n            return TranscriptionResult(\n                text=_text,\n                language=detected_language,\n                confidence=confidence,\n                processing_time=time.time() - start_time\n            )\n            \n        except Exception as e:\n            logger.error(f\"Transcription error: {e}\")\n            return TranscriptionResult(\n                text=f\"Transcription error: {e}\",\n                language=\"en\",\n                confidence=0.0,\n                processing_time=time.time() - start_time\n            )\n\n    def _transcribe_with_direct_fix(self, audio_path: str, language: str = None):\n       \n        # Force model to float32 permanently\n        self._force_model_to_float32()\n        \n        # Set torch default dtype to float32\n        original_dtype = torch.get_default_dtype()\n        torch.set_default_dtype(torch.float32)\n        \n        # Patch tensor creation functions\n        original_tensor = torch.tensor\n        original_from_numpy = torch.from_numpy\n        \n        def patched_tensor(*args, **kwargs):\n            if 'dtype' not in kwargs:\n                kwargs['dtype'] = torch.float32\n            return original_tensor(*args, **kwargs)\n        \n        def patched_from_numpy(*args, **kwargs):\n            result = original_from_numpy(*args, **kwargs)\n            return result.float()\n        \n        # Apply patches\n        torch.tensor = patched_tensor\n        torch.from_numpy = patched_from_numpy\n        \n        try:\n            # Force disable any fp16 usage\n            result = self.model_manager.whisper_model.transcribe(\n                audio_path,\n                language='en',\n                task=\"translate\" if language and language != 'en' else \"transcribe\",\n                fp16=False,\n                temperature=0.0,\n                best_of=5,\n                beam_size=5,\n                patience=1.0,\n                condition_on_previous_text=True,\n                verbose=False\n            )\n            return result\n            \n        finally:\n            # Restore original functions\n            torch.tensor = original_tensor\n            torch.from_numpy = original_from_numpy\n            torch.set_default_dtype(original_dtype)\n\n    def _force_model_to_float32(self):\n        # Force the entire model to float32 precision\n        try:\n            model = self.model_manager.whisper_model\n            \n            # Convert all model parameters to float32\n            model.float()\n            \n            # Ensure model is on correct device\n            model.to(self.device)\n            \n            # Force all submodules to float32\n            for module in model.modules():\n                if hasattr(module, 'float'):\n                    module.float()\n            \n            # Special handling for specific Whisper components\n            if hasattr(model, 'encoder'):\n                model.encoder.float()\n            if hasattr(model, 'decoder'):\n                model.decoder.float()\n                \n            logger.info(\"Successfully forced model to float32\")\n            \n        except Exception as e:\n            logger.warning(f\"Failed to force model to float32: {e}\")\n\n    def _calculate_confidence(self, result: dict) -> float:\n        # Calculate confidence from Whisper segments\n        try:\n            if \"segments\" not in result or not result[\"segments\"]:\n                return 0.7\n\n            confidences = []\n            for segment in result[\"segments\"]:\n                if \"avg_logprob\" in segment and segment[\"avg_logprob\"] is not None:\n                    log_prob = float(segment[\"avg_logprob\"])\n                    conf = min(1.0, max(0.0, np.exp(log_prob)))\n                    confidences.append(conf)\n                elif \"no_speech_prob\" in segment and segment[\"no_speech_prob\"] is not None:\n                    no_speech = float(segment[\"no_speech_prob\"])\n                    conf = max(0.0, 1.0 - no_speech)\n                    confidences.append(conf)\n\n            if confidences:\n                return float(np.mean(confidences))\n            else:\n                return 0.7\n                \n        except Exception as e:\n            logger.error(f\"Confidence calculation error: {e}\")\n            return 0.7\n\n# Creating a wrapper to bypass encoding issue\nclass WhisperFloat32Wrapper:\n    # Wrapper that ensures all Whisper operations use float32\n    \n    def __init__(self, original_model):\n        self.original_model = original_model\n        self._ensure_float32()\n    \n    def _ensure_float32(self):\n        # Ensure model is completely in float32\n        self.original_model.float()\n        for param in self.original_model.parameters():\n            param.data = param.data.float()\n    \n    def transcribe(self, audio, **kwargs):\n        kwargs['fp16'] = False      \n        # If audio is a tensor, ensure it's float32\n        if isinstance(audio, torch.Tensor):\n            audio = audio.float()\n        \n        # Set default dtype context with correct device_type\n        device_type = 'cuda' if torch.cuda.is_available() else 'cpu'\n        with torch.autocast(device_type=device_type, enabled=False):\n            return self.original_model.transcribe(audio, **kwargs)\n\n    def __getattr__(self, name):\n        # Delegate all other attributes to original model\n        return getattr(self.original_model, name)\n\n# Initialization - wrapping the model without setting property\nclass ASRWithWrappedModel(ASRWithNgram):\n    # ASR that wraps the whisper model internally\n    \n    def __init__(self, model_manager: ModelManager):\n        super().__init__(model_manager)\n        # Create wrapped model internally\n        if model_manager.whisper_model:\n            self.wrapped_model = WhisperFloat32Wrapper(model_manager.whisper_model)\n        else:\n            self.wrapped_model = None\n    \n    def _transcribe_with_direct_fix(self, audio_path: str, language: str = None):\n        # Direct fix using wrapped model\n        \n        if not self.wrapped_model:\n            raise Exception(\"Wrapped model not available\")\n        \n        # Set torch default dtype to float32\n        original_dtype = torch.get_default_dtype()\n        torch.set_default_dtype(torch.float32)\n        \n        try:\n            # Use wrapped model instead of original\n            result = self.wrapped_model.transcribe(\n                audio_path,\n                language='en',\n                task=\"translate\" if language and language != 'en' else \"transcribe\",\n                fp16=False,\n                temperature=0.0,\n                best_of=5,\n                beam_size=5,\n                patience=1.0,\n                condition_on_previous_text=True,\n                verbose=False\n            )\n            return result\n            \n        finally:\n            torch.set_default_dtype(original_dtype)\n\n_asr = ASRWithWrappedModel(model_manager)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:55:35.535833Z","iopub.execute_input":"2025-07-14T07:55:35.536060Z","iopub.status.idle":"2025-07-14T07:56:20.623955Z","shell.execute_reply.started":"2025-07-14T07:55:35.536035Z","shell.execute_reply":"2025-07-14T07:56:20.623330Z"}},"outputs":[{"name":"stdout","text":"Loading Whisper model...\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████████████████████████████████| 1.42G/1.42G [00:29<00:00, 52.3MiB/s]\n","output_type":"stream"},{"name":"stdout","text":"Whisper Medium loaded\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Translation with NLLB-only\nclass NLLBTranslator:\n    \"\"\" translator using only NLLB-200\"\"\"\n    \n    def __init__(self, model_manager: ModelManager):\n        self.model_manager = model_manager\n        self.nllb_map = {\n            'hi': 'hin_Deva',\n            'ta': 'tam_Taml', \n            'en': 'eng_Latn'\n        }\n    \n    def translate_to_english(self, text: str, source_language: str) -> str:\n        \"\"\" translation using NLLB-200 only\"\"\"\n        try:\n            if not text or not text.strip():\n                return text\n            \n            # If already English, return as is\n            if source_language == 'en':\n                return self._enhance_text(text)\n            \n            if not self.model_manager.translator:\n                return self._enhance_text(text)\n            \n            src_lang = self.nllb_map.get(source_language, 'hin_Deva')\n            \n            # Split into sentences for better translation\n            sentences = self._split_sentences(text)\n            translated_sentences = []\n            \n            for sentence in sentences:\n                if not sentence.strip():\n                    continue\n                \n                try:\n                    result = self.model_manager.translator(\n                        sentence,\n                        src_lang=src_lang,\n                        tgt_lang='eng_Latn',\n                        max_length=512,\n                        num_beams=4,\n                        early_stopping=True,\n                        do_sample=False\n                    )\n                    \n                    translated_text = result[0]['translation_text']\n                    translated_sentences.append(translated_text.strip())\n                    \n                except Exception as e:\n                    logger.warning(f\"Sentence translation failed: {e}\")\n                    translated_sentences.append(sentence)\n            \n            # Reconstruct text\n            full_translation = '. '.join(translated_sentences)\n            if not full_translation.endswith(('.', '!', '?')):\n                full_translation += '.'\n            \n            return self._enhance_text(full_translation)\n            \n        except Exception as e:\n            logger.error(f\"Translation error: {e}\")\n            return self._enhance_text(text)\n    \n    def _split_sentences(self, text: str) -> List[str]:\n        \"\"\"Split text into sentences\"\"\"\n        try:\n            sentences = re.split(r'[.!?]+', text)\n            return [s.strip() for s in sentences if s.strip()]\n        except Exception as e:\n            logger.error(f\"Sentence splitting error: {e}\")\n            return [text]\n    \n    def _enhance_text(self, text: str) -> str:\n        \"\"\"Enhance text with proper punctuation and formatting\"\"\"\n        try:\n            if not text:\n                return text\n            \n            # Normalize whitespace\n            text = re.sub(r'\\s+', ' ', text.strip())\n            \n            # Ensure proper sentence ending\n            if text and text[-1] not in '.!?':\n                question_words = ['what', 'when', 'where', 'who', 'why', 'how']\n                if any(word in text.lower() for word in question_words):\n                    text += '?'\n                else:\n                    text += '.'\n            \n            # Capitalize first letter\n            if text:\n                text = text[0].upper() + text[1:] if len(text) > 1 else text.upper()\n            \n            return text\n        except Exception as e:\n            logger.error(f\"Text enhancement error: {e}\")\n            return text\n\n# Initialize  translator\n_translator = NLLBTranslator(model_manager)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:56:20.624619Z","iopub.execute_input":"2025-07-14T07:56:20.624823Z","iopub.status.idle":"2025-07-14T07:56:20.635488Z","shell.execute_reply.started":"2025-07-14T07:56:20.624805Z","shell.execute_reply":"2025-07-14T07:56:20.634797Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Intent Classification\nclass IntentClassifier:    \n    def __init__(self, model_manager: ModelManager):\n        self.model_manager = model_manager\n    \n    def classify_intent(self, text: str) -> Tuple[str, float, Dict[str, float]]:\n        # Intent classification with multiple strategies\n        try:\n            if not self.model_manager.intent_model or not self.model_manager.intent_embeddings:\n                return self._fallback_classification(text)\n            \n            # Preprocess text\n            processed_text = self._preprocess_text(text)\n            \n            # Semantic similarity approach\n            semantic_scores = self._semantic_classification(processed_text)\n            \n            # Keyword-based approach\n            keyword_scores = self._keyword_classification(processed_text)\n            \n            # Combine scores with weights (70% semantic, 30% keyword)\n            combined_scores = {}\n            for intent in SERVICE_INTENTS.keys():\n                semantic_score = semantic_scores.get(intent, 0.0)\n                keyword_score = keyword_scores.get(intent, 0.0)\n                combined_scores[intent] = 0.7 * semantic_score + 0.3 * keyword_score\n            \n            # Get best intent\n            best_intent = max(combined_scores, key=combined_scores.get)\n            confidence = combined_scores[best_intent]\n            \n            # Apply urgency boost\n            urgency_boost = self._calculate_urgency_boost(processed_text, best_intent)\n            final_confidence = min(confidence + urgency_boost, 1.0)\n            \n            # Sort all scores\n            sorted_scores = dict(sorted(combined_scores.items(), key=lambda x: x[1], reverse=True))\n            \n            return best_intent, final_confidence, sorted_scores\n            \n        except Exception as e:\n            logger.error(f\"Intent classification error: {e}\")\n            return self._fallback_classification(text)\n    \n    def _preprocess_text(self, text: str) -> str:\n        # Advanced text preprocessing\n        try:\n            text = text.lower().strip()\n            text = re.sub(r'[^\\w\\s.!?]', ' ', text)\n            text = re.sub(r'\\s+', ' ', text)\n            \n            # Remove common stop words but keep important ones\n            stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}\n            words = text.split()\n            filtered_words = [word for word in words if word not in stop_words or len(word) > 3]\n            \n            return ' '.join(filtered_words)\n        except Exception as e:\n            logger.error(f\"Text preprocessing error: {e}\")\n            return text\n    \n    def _semantic_classification(self, text: str) -> Dict[str, float]:\n        # Semantic similarity-based classification\n        try:\n            text_embedding = self.model_manager.intent_model.encode(\n                text, convert_to_tensor=True, device=device\n            )\n            \n            similarities = {}\n            for intent, intent_emb in self.model_manager.intent_embeddings.items():\n                similarity = torch.nn.functional.cosine_similarity(\n                    text_embedding.unsqueeze(0), intent_emb.unsqueeze(0)\n                ).item()\n                similarities[intent] = max(0.0, similarity)\n            \n            return similarities\n        except Exception as e:\n            logger.error(f\"Semantic classification error: {e}\")\n            return {}\n    \n    def _keyword_classification(self, text: str) -> Dict[str, float]:\n        # Keyword-based classification\n        try:\n            scores = {}\n            \n            for intent, intent_data in SERVICE_INTENTS.items():\n                keywords = intent_data['keywords']\n                urgency_indicators = intent_data.get('urgency_indicators', [])\n                \n                keyword_matches = sum(1 for keyword in keywords if keyword in text)\n                urgency_matches = sum(1 for indicator in urgency_indicators if indicator in text)\n                \n                keyword_score = keyword_matches / len(keywords) if keywords else 0\n                urgency_score = urgency_matches / len(urgency_indicators) if urgency_indicators else 0\n                \n                total_score = 0.8 * keyword_score + 0.2 * urgency_score\n                scores[intent] = total_score\n            \n            return scores\n        except Exception as e:\n            logger.error(f\"Keyword classification error: {e}\")\n            return {}\n    \n    def _calculate_urgency_boost(self, text: str, intent: str) -> float:\n        # Calculate urgency-based confidence boost\n        try:\n            high_urgency = ['urgent', 'emergency', 'asap', 'immediately', 'critical', 'help']\n            medium_urgency = ['quickly', 'soon', 'today', 'fast', 'problem', 'issue']\n            \n            intent_urgency = SERVICE_INTENTS.get(intent, {}).get('urgency_indicators', [])\n            \n            high_count = sum(1 for word in high_urgency if word in text)\n            medium_count = sum(1 for word in medium_urgency if word in text)\n            intent_urgency_count = sum(1 for word in intent_urgency if word in text)\n            \n            if high_count > 0 or intent_urgency_count > 0:\n                return 0.15\n            elif medium_count > 0:\n                return 0.08\n            else:\n                return 0.0\n        except Exception as e:\n            logger.error(f\"Urgency boost calculation error: {e}\")\n            return 0.0\n    \n    def _fallback_classification(self, text: str) -> Tuple[str, float, Dict[str, float]]:\n        # Fallback classification using simple keyword matching\n        try:\n            text_lower = text.lower()\n            scores = {}\n            \n            for intent, intent_data in SERVICE_INTENTS.items():\n                keywords = intent_data['keywords']\n                matches = sum(1 for keyword in keywords if keyword in text_lower)\n                if matches > 0:\n                    scores[intent] = matches / len(keywords)\n            \n            if scores:\n                best_intent = max(scores, key=scores.get)\n                confidence = min(scores[best_intent] * 3, 1.0)\n                sorted_scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n                return best_intent, confidence, sorted_scores\n            else:\n                return \"General Services\", 0.5, {\"General Services\": 0.5}\n        except Exception as e:\n            logger.error(f\"Fallback classification error: {e}\")\n            return \"General Services\", 0.5, {\"General Services\": 0.5}\n    \n    def get_urgency_level(self, text: str) -> str:\n        # Urgency level detection\n        try:\n            high_urgency = ['urgent', 'emergency', 'asap', 'immediately', 'critical', 'help']\n            medium_urgency = ['quickly', 'soon', 'today', 'fast', 'problem', 'issue', 'needed']\n            \n            text_lower = text.lower()\n            \n            high_count = sum(1 for word in high_urgency if word in text_lower)\n            medium_count = sum(1 for word in medium_urgency if word in text_lower)\n            \n            exclamation_count = text.count('!')\n            caps_ratio = sum(1 for c in text if c.isupper()) / len(text) if text else 0\n            \n            if high_count >= 1 or exclamation_count >= 2 or caps_ratio > 0.3:\n                return \"High\"\n            elif medium_count >= 1 or exclamation_count >= 1:\n                return \"Medium\"\n            else:\n                return \"Low\"\n        except Exception as e:\n            logger.error(f\"Urgency level detection error: {e}\")\n            return \"Low\"\n\n# Initializing intent classifier\n_classifier = IntentClassifier(model_manager)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:56:20.636326Z","iopub.execute_input":"2025-07-14T07:56:20.636598Z","iopub.status.idle":"2025-07-14T07:56:20.663154Z","shell.execute_reply.started":"2025-07-14T07:56:20.636576Z","shell.execute_reply":"2025-07-14T07:56:20.662650Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Main Service Request Analyzer with Chatbot Integration\nclass ServiceRequestAnalyzer:\n    # Main service request analysis pipeline with chatbot integration\n\n    def __init__(self):\n        self.asr = _asr\n        self.translator = _translator\n        self.classifier = _classifier\n        self.chatbot = chatbot\n\n    def analyze_request(self, \n                        text_input: Optional[str] = None,\n                        audio_file: Optional[dict] = None,\n                        chatbot_context: Optional[Dict] = None) -> AnalysisResult:\n        # Analysis pipeline with chatbot integration\n        start_time = time.time()\n        detected_languages = ['en']\n        original_text = \"\"\n\n        try:\n            # Process audio input\n            if audio_file is not None:\n                transcription_result = self._process_audio_file(audio_file)\n\n                if \"error\" in transcription_result.text.lower():\n                    return self._create_error_result(transcription_result.text, start_time)\n\n                original_text = transcription_result.text\n                detected_languages = [transcription_result.language]\n\n            elif text_input:\n                text_input = text_input.strip()\n                if not text_input:\n                    raise ValueError(\"Empty text input\")\n\n                detected_languages = self._detect_languages(text_input)\n                original_text = self._enhance_text(text_input, detected_languages[0])\n\n            else:\n                raise ValueError(\"No input provided\")\n\n            if not original_text or not original_text.strip():\n                raise ValueError(\"No valid text to process\")\n\n            # Translation using NLLB-only\n            translated_text = original_text\n            primary_lang = detected_languages[0] if detected_languages else 'en'\n\n            if primary_lang != 'en':\n                translated_text = self.translator.translate_to_english(original_text, primary_lang)\n\n            # Intent classification\n            intent, confidence, all_scores = self.classifier.classify_intent(translated_text)\n            urgency = self.classifier.get_urgency_level(translated_text)\n\n            # Get top 3 matches\n            top_matches = dict(list(all_scores.items())[:3])\n\n            # Include chatbot context\n            context = chatbot_context or {}\n\n            return AnalysisResult(\n                original_text=original_text,\n                translated_text=translated_text,\n                detected_languages=detected_languages,\n                intent=intent,\n                confidence=confidence,\n                urgency=urgency,\n                top_matches=top_matches,\n                processing_time=time.time() - start_time,\n                chatbot_context=context\n            )\n\n        except Exception as e:\n            logger.error(f\"Analysis error: {e}\")\n            return self._create_error_result(str(e), start_time)\n\n    def _process_audio_file(self, audio_file: dict) -> TranscriptionResult:\n        # Process uploaded audio file\n        try:\n            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:\n                temp_file.write(audio_file['content'])\n                temp_file.flush()\n\n            result = self.asr.transcribe_with_ngram_fusion(temp_file.name)\n\n            # Clean up\n            try:\n                os.unlink(temp_file.name)\n            except Exception:\n                pass\n\n            return result\n\n        except Exception as e:\n            logger.error(f\"Audio processing error: {e}\")\n            return TranscriptionResult(\n                text=f\"Audio processing error: {e}\",\n                language=\"en\",\n                confidence=0.0,\n                processing_time=0.0\n            )\n\n    def _detect_languages(self, text: str) -> List[str]:\n        # Detect languages in text\n        try:\n            patterns = {\n                'hi': r'[ऀ-ॿ]+',\n                'ta': r'[\\u0b80-\\u0bff]+',\n                'en': r'[a-zA-Z]+'\n            }\n\n            detected_langs = []\n            for lang, pattern in patterns.items():\n                if re.search(pattern, text):\n                    detected_langs.append(lang)\n\n            return detected_langs if detected_langs else ['en']\n        except Exception as e:\n            logger.error(f\"Language detection error: {e}\")\n            return ['en']\n\n    def _enhance_text(self, text: str, language: str) -> str:\n        # Enhance text with proper formatting\n        try:\n            text = re.sub(r'\\s+', ' ', text.strip())\n\n            if text and text[-1] not in '.!?':\n                question_words = ['what', 'when', 'where', 'who', 'why', 'how', 'क्या', 'कब', 'कहाँ']\n                if any(word in text.lower() for word in question_words):\n                    text += '?'\n                else:\n                    text += '.'\n\n            return text\n        except Exception as e:\n            logger.error(f\"Text enhancement error: {e}\")\n            return text\n\n    def _create_error_result(self, error_msg: str, start_time: float) -> AnalysisResult:\n        # Create error result\n        return AnalysisResult(\n            original_text=error_msg,\n            translated_text=error_msg,\n            detected_languages=['en'],\n            intent=\"General Services\",\n            confidence=0.0,\n            urgency=\"Low\",\n            top_matches={\"General Services\": 0.0},\n            processing_time=time.time() - start_time,\n            chatbot_context={}\n        )\n\n# Initialize service request analyzer\nanalyzer = ServiceRequestAnalyzer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:56:20.664000Z","iopub.execute_input":"2025-07-14T07:56:20.664245Z","iopub.status.idle":"2025-07-14T07:56:20.688112Z","shell.execute_reply.started":"2025-07-14T07:56:20.664229Z","shell.execute_reply":"2025-07-14T07:56:20.687455Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Main User Interface\nimport ipywidgets as widgets\nfrom IPython.display import display, HTML\n\nclass ImprovedServiceUI:    \n    def __init__(self, analyzer: ServiceRequestAnalyzer):\n        self.analyzer = analyzer\n        self.chatbot = chatbot\n        self.setup_ui()\n    \n    def setup_ui(self):\n        display(HTML(\"\"\"\n        <style>\n        body {\n            background-color: #1a1a1a !important;\n            color: #ffffff !important;\n        }\n        .widget-text, .widget-textarea, .widget-button {\n            font-family: 'Helvetica', Arial, sans-serif !important;\n            background-color: #2d2d2d !important;\n            color: #ffffff !important;\n            border: 1px solid #444444 !important;\n        }\n        .widget-button {\n            background-color: #0DC4D9 !important;\n            color: #ffffff !important;\n            border: none !important;\n            padding: 12px 24px !important;\n            border-radius: 6px !important;\n            font-size: 14px !important;\n            font-weight: 500 !important;\n            min-width: 140px !important;\n            transition: background-color 0.3s ease !important;\n        }\n        .widget-button:hover {\n            background-color: #FF8C00 !important;\n        }\n        .main-container {\n            display: flex;\n            flex-direction: column;\n            gap: 20px;\n            background-color: #1a1a1a;\n        }\n        .content-container {\n            display: flex;\n            gap: 20px;\n            align-items: flex-start;\n        }\n        .left-panel {\n            flex: 1;\n            width: 50%;\n            min-width: 50%;\n        }\n        .right-panel {\n            flex: 1;\n            width: 50%;\n            min-width: 50%;\n            border-left: 2px solid #444444;\n            padding-left: 20px;\n        }\n        .section-header {\n            background-color: #333333;\n            padding: 8px 12px;\n            border-radius: 5px;\n            margin: 15px 0 10px 0;\n            border-left: 3px solid #0DC4D9;\n        }\n        .main-header {\n            text-align: center;\n            padding: 20px;\n            background: linear-gradient(135deg, #2d2d2d 0%, #3d3d3d 100%);\n            border-radius: 8px;\n            margin-bottom: 20px;\n            border: 1px solid #444444;\n        }\n        .button-group {\n            display: flex;\n            gap: 10px;\n            margin: 15px 0;\n            flex-wrap: wrap;\n        }\n        .jupyter-widgets {\n            background-color: #1a1a1a !important;\n        }\n        </style>\n        \"\"\"))\n        \n        self.header = widgets.HTML(\n            value=\"\"\"\n            <div class=\"main-header\">\n                <h1 style=\"color: #ffffff; margin-bottom: 8px; font-family: 'Helvetica', Arial, sans-serif; font-size: 32px; font-weight: 700;\">Multilingual Service Request Analyzer</h1>\n                <p style=\"color: #cccccc; margin-top: 0; font-family: 'Helvetica', Arial, sans-serif; font-size: 18px;\">Supports Hindi, Tamil, and English</p>\n            </div>\n            \"\"\"\n        )\n        \n        self.text_input = widgets.Textarea(\n            placeholder=\"Enter your service request in Hindi, Tamil, or English...\",\n            layout=widgets.Layout(width='99%', height='120px')\n        )\n        \n        self.audio_upload = widgets.FileUpload(\n            accept='.wav,.mp3,.m4a,.ogg',\n            multiple=False,\n            description='Upload Audio'\n        )\n        \n        self.analyze_text_btn = widgets.Button(\n            description=\"Analyze Text\",\n            button_style='primary',\n            layout=widgets.Layout(width='150px', height='45px')\n        )\n        \n        self.analyze_audio_btn = widgets.Button(\n            description=\"Process Audio\",\n            button_style='success',\n            layout=widgets.Layout(width='150px', height='45px')\n        )\n        \n        self.clear_btn = widgets.Button(\n            description=\"Clear All\",\n            button_style='warning',\n            layout=widgets.Layout(width='120px', height='45px')\n        )\n        \n        self.results_display = widgets.HTML(\n            value=\"<p style='color: #cccccc; padding: 20px; text-align: center; font-family: Helvetica, Arial, sans-serif;'>Results will appear here after analysis...</p>\"\n        )\n        \n        self.chat_input = widgets.Text(\n            placeholder=\"Chat with assistant...\",\n            layout=widgets.Layout(width='100%')\n        )\n        \n        self.chat_send_btn = widgets.Button(\n            description=\"Send\",\n            button_style='info',\n            layout=widgets.Layout(width='80px', height='35px')\n        )\n        \n        self.chat_output = widgets.HTML(\n            value=\"\"\"\n            <div style=\"background: #2d2d2d; padding: 15px; border-radius: 5px; min-height: 200px; max-height: 400px; overflow-y: auto; border: 1px solid #444444;\">\n                <p style=\"color: #ffffff; font-family: 'Helvetica', Arial, sans-serif;\"><strong>Assistant:</strong> Hello! How can I help you today?</p>\n            </div>\n            \"\"\"\n        )\n        \n        self.analyze_text_btn.on_click(self._on_analyze_text)\n        self.analyze_audio_btn.on_click(self._on_analyze_audio)\n        self.clear_btn.on_click(self._on_clear)\n        self.chat_send_btn.on_click(self._on_chat_send)\n        self.chat_input.on_submit(self._on_chat_send)\n        \n        self._display_ui()\n    \n    def _display_ui(self):\n        left_panel = widgets.VBox([\n            widgets.HTML('<div class=\"section-header\"><h3 style=\"margin: 0; color: #ffffff; font-family: Helvetica, Arial, sans-serif;\">Text Input</h3></div>'),\n            self.text_input,\n            widgets.HTML('<div class=\"section-header\"><h3 style=\"margin: 0; color: #ffffff; font-family: Helvetica, Arial, sans-serif;\">Audio Input</h3></div>'),\n            self.audio_upload,\n            widgets.HTML('<div class=\"section-header\"><h3 style=\"margin: 0; color: #ffffff; font-family: Helvetica, Arial, sans-serif;\">Actions</h3></div>'),\n            widgets.HBox([\n                self.analyze_text_btn,\n                self.analyze_audio_btn,\n                self.clear_btn\n            ], layout=widgets.Layout(gap='10px', overflow='hidden', flex_flow='row wrap'))\n        ], layout=widgets.Layout(width='50%', flex='1 1 50%'))\n        \n        right_panel = widgets.VBox([\n            widgets.HTML('<div class=\"section-header\"><h3 style=\"margin: 0; color: #ffffff; font-family: Helvetica, Arial, sans-serif;\">AI Assistant</h3></div>'),\n            self.chat_output,\n            widgets.HTML('<h4 style=\"margin: 15px 0 5px 0; color: #ffffff; font-family: Helvetica, Arial, sans-serif;\">Send Message</h4>'),\n            widgets.HBox([\n                self.chat_input,\n                self.chat_send_btn\n            ], layout=widgets.Layout(gap='10px'))\n        ], layout=widgets.Layout(width='50%', flex='1 1 50%'))\n        \n        content_container = widgets.HBox([\n            left_panel,\n            right_panel\n        ], layout=widgets.Layout(gap='20px', display='flex', align_items='stretch'))\n        \n        results_section = widgets.VBox([\n            widgets.HTML('<div class=\"section-header\"><h3 style=\"margin: 0; color: #ffffff; font-family: Helvetica, Arial, sans-serif;\">Analysis Results</h3></div>'),\n            self.results_display\n        ])\n        \n        main_container = widgets.VBox([\n            self.header,\n            content_container,\n            results_section\n        ])\n\n        display(main_container)\n    \n    def _on_analyze_text(self, button):\n        try:\n            text = self.text_input.value.strip()\n            if not text:\n                self.results_display.value = \"<p style='color: #ff6b6b; padding: 15px; font-family: Helvetica, Arial, sans-serif;'>Please enter some text to analyze.</p>\"\n                return\n            self.results_display.value = \"<p style='color: #4dabf7; padding: 15px; font-family: Helvetica, Arial, sans-serif;'>Processing text input...</p>\"\n            result = self.analyzer.analyze_request(text_input=text)\n            self._display_results(result)\n        except Exception as e:\n            self.results_display.value = f\"<p style='color: #ff6b6b; padding: 15px; font-family: Helvetica, Arial, sans-serif;'>Error: {e}</p>\"\n    \n    def _on_analyze_audio(self, button):\n        # Handle audio analysis with optimized processing\n        try:\n            if not self.audio_upload.value:\n                self.results_display.value = \"<p style='color: #ff6b6b; padding: 15px; font-family: Helvetica, Arial, sans-serif;'>Please upload an audio file first.</p>\"\n                return\n    \n            # Show processing indicator\n            self.results_display.value = \"<p style='color: #4dabf7; padding: 15px; font-family: Helvetica, Arial, sans-serif;'>Processing audio file... This may take a moment.</p>\"\n    \n            # Get uploaded file - do not use 'metadata'\n            if isinstance(self.audio_upload.value, tuple) and len(self.audio_upload.value) > 0:\n                uploaded_file = self.audio_upload.value[0]\n                audio_data = {\n                    'content': uploaded_file['content']\n                    # Optionally add: 'name': uploaded_file.get('name'), 'type': uploaded_file.get('type')\n                }\n            else:\n                self.results_display.value = \"<div>No file uploaded.</div>\"\n                return\n    \n            # Process audio with optimized pipeline\n            result = self.analyzer.analyze_request(audio_file=audio_data)\n            self._display_results(result)\n    \n        except Exception as e:\n            self.results_display.value = f\"<p style='color: #ff6b6b; padding: 15px; font-family: Helvetica, Arial, sans-serif;'>Audio processing error: {e}</p>\"\n\n    def _on_clear(self, button):\n        self.text_input.value = \"\"\n        self.audio_upload.value = ()\n        self.chat_input.value = \"\"\n        self.results_display.value = \"<p style='color: #cccccc; padding: 20px; text-align: center; font-family: Helvetica, Arial, sans-serif;'>All inputs cleared. Ready for new analysis.</p>\"\n        self.chat_output.value = \"\"\"\n        <div style=\"background: #2d2d2d; padding: 15px; border-radius: 5px; min-height: 50px; max-height: 50px; overflow-y: auto; border: 1px solid #444444;\">\n            <p style=\"color: #ffffff; font-family: 'Helvetica', Arial, sans-serif;\"><strong>Assistant:</strong> Hello! How can I help you today?</p>\n        </div>\n        \"\"\"\n        self.chatbot.reset_conversation()\n    \n    def _on_chat_send(self, button=None):\n        try:\n            user_message = self.chat_input.value.strip()\n            if not user_message:\n                return\n            response = self.chatbot.process_user_input(user_message)\n            current_chat = self.chat_output.value\n            new_message = f\"\"\"\n            <div style=\"margin: 10px 0; padding: 10px; background: #3d3d3d; border-radius: 5px; border-left: 3px solid #4dabf7;\">\n                <p style=\"margin: 0; color: #ffffff; font-family: 'Helvetica', Arial, sans-serif;\"><strong>You:</strong> {user_message}</p>\n            </div>\n            <div style=\"margin: 10px 0; padding: 10px; background: #1e3a8a; border-radius: 5px; border-left: 3px solid #60a5fa;\">\n                <p style=\"margin: 0; color: #ffffff; font-family: 'Helvetica', Arial, sans-serif;\"><strong>Assistant:</strong> {response.message}</p>\n            </div>\n            \"\"\"\n            self.chat_output.value = f\"\"\"\n            <div style=\"background: #2d2d2d; padding: 15px; border-radius: 5px; min-height: 200px; max-height: 400px; overflow-y: auto; border: 1px solid #444444;\">\n                {new_message}\n            </div>\n            \"\"\"\n            self.chat_input.value = \"\"\n            if response.next_step == 'processing' and response.collected_data.get('description'):\n                result = self.analyzer.analyze_request(\n                    text_input=response.collected_data['description'],\n                    chatbot_context=response.collected_data\n                )\n                self._display_results(result)\n        except Exception as e:\n            self.chat_output.value = f\"\"\"\n            <div style=\"background: #2d2d2d; padding: 15px; border-radius: 5px; border: 1px solid #444444;\">\n                <p style=\"color: #ff6b6b; font-family: 'Helvetica', Arial, sans-serif;\"><strong>Error:</strong> {e}</p>\n            </div>\n            \"\"\"\n    \n    def _display_results(self, result):\n        try:\n            lang_map = {'hi': 'Hindi', 'ta': 'Tamil', 'en': 'English'}\n            detected_names = [lang_map.get(lang, lang) for lang in result.detected_languages]\n            conf_color = \"#51cf66\" if result.confidence > 0.7 else \"#ffd43b\" if result.confidence > 0.4 else \"#ff6b6b\"\n            urgency_colors = {\"High\": \"#ff6b6b\", \"Medium\": \"#ffd43b\", \"Low\": \"#51cf66\"}\n            urgency_color = urgency_colors.get(result.urgency, \"#adb5bd\")\n            results_html = f\"\"\"\n            <div style=\"border: 1px solid #444444; border-radius: 8px; padding: 20px; background: #2d2d2d; margin: 10px 0; font-family: 'Helvetica', Arial, sans-serif;\">\n                <h4 style=\"color: #ffffff; margin-top: 0; border-bottom: 2px solid #4dabf7; padding-bottom: 10px;\">Analysis Results</h4>\n                <table style=\"width: 100; border-collapse: collapse; margin: 15px 0;\">\n                    <tr style=\"background: #3d3d3d;\">\n                        <td style=\"padding: 12px; font-weight: bold; border: 1px solid #555555; width: 30%; color: #ffffff;\">Original Text</td>\n                        <td style=\"padding: 12px; border: 1px solid #555555; color: #ffffff;\">{result.original_text}</td>\n                    </tr>\n                    <tr>\n                        <td style=\"padding: 12px; font-weight: bold; border: 1px solid #555555; color: #ffffff;\">Translated Text</td>\n                        <td style=\"padding: 12px; border: 1px solid #555555; color: #ffffff;\">{result.translated_text}</td>\n                    </tr>\n                    <tr style=\"background: #3d3d3d;\">\n                        <td style=\"padding: 12px; font-weight: bold; border: 1px solid #555555; color: #ffffff;\">Detected Language</td>\n                        <td style=\"padding: 12px; border: 1px solid #555555; color: #ffffff;\">{\", \".join(detected_names)}</td>\n                    </tr>\n                    <tr>\n                        <td style=\"padding: 12px; font-weight: bold; border: 1px solid #555555; color: #ffffff;\">Service Category</td>\n                        <td style=\"padding: 12px; border: 1px solid #555555;\">\n                            <span style=\"background: #4dabf7; color: #ffffff; padding: 4px 8px; border-radius: 4px; font-size: 12px;\">{result.intent}</span>\n                        </td>\n                    </tr>\n                    <tr style=\"background: #3d3d3d;\">\n                        <td style=\"padding: 12px; font-weight: bold; border: 1px solid #555555; color: #ffffff;\">Urgency Level</td>\n                        <td style=\"padding: 12px; border: 1px solid #555555;\">\n                            <span style=\"color: {urgency_color}; font-weight: bold;\">{result.urgency}</span>\n                        </td>\n                    </tr>\n                    <tr>\n                        <td style=\"padding: 12px; font-weight: bold; border: 1px solid #555555; color: #ffffff;\">Confidence</td>\n                        <td style=\"padding: 12px; border: 1px solid #555555;\">\n                            <span style=\"color: {conf_color}; font-weight: bold;\">{result.confidence:.1%}</span>\n                        </td>\n                    </tr>\n                    <tr style=\"background: #3d3d3d;\">\n                        <td style=\"padding: 12px; font-weight: bold; border: 1px solid #555555; color: #ffffff;\">Processing Time</td>\n                        <td style=\"padding: 12px; border: 1px solid #555555; color: #ffffff;\">{result.processing_time:.2f}s</td>\n                    </tr>\n                </table>\n                <h5 style=\"color: #ffffff; margin: 20px 0 10px 0;\">Top Service Matches</h5>\n                <ul style=\"margin: 0; padding-left: 20px; color: #ffffff;\">\n            \"\"\"\n            for intent, score in list(result.top_matches.items())[:3]:\n                results_html += f\"<li style='margin: 5px 0; color: #ffffff;'><strong>{intent}:</strong> {score:.1%}</li>\"\n            results_html += \"\"\"\n                </ul>\n            </div>\n            \"\"\"\n            self.results_display.value = results_html\n        except Exception as e:\n            self.results_display.value = f\"<p style='color: #ff6b6b; padding: 15px; font-family: Helvetica, Arial, sans-serif;'>Display error: {e}</p>\"\n\n# Initialize the UI\nui = ImprovedServiceUI(analyzer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:56:20.689723Z","iopub.execute_input":"2025-07-14T07:56:20.689965Z","iopub.status.idle":"2025-07-14T07:56:20.758294Z","shell.execute_reply.started":"2025-07-14T07:56:20.689950Z","shell.execute_reply":"2025-07-14T07:56:20.757583Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n        <style>\n        body {\n            background-color: #1a1a1a !important;\n            color: #ffffff !important;\n        }\n        .widget-text, .widget-textarea, .widget-button {\n            font-family: 'Helvetica', Arial, sans-serif !important;\n            background-color: #2d2d2d !important;\n            color: #ffffff !important;\n            border: 1px solid #444444 !important;\n        }\n        .widget-button {\n            background-color: #0DC4D9 !important;\n            color: #ffffff !important;\n            border: none !important;\n            padding: 12px 24px !important;\n            border-radius: 6px !important;\n            font-size: 14px !important;\n            font-weight: 500 !important;\n            min-width: 140px !important;\n            transition: background-color 0.3s ease !important;\n        }\n        .widget-button:hover {\n            background-color: #FF8C00 !important;\n        }\n        .main-container {\n            display: flex;\n            flex-direction: column;\n            gap: 20px;\n            background-color: #1a1a1a;\n        }\n        .content-container {\n            display: flex;\n            gap: 20px;\n            align-items: flex-start;\n        }\n        .left-panel {\n            flex: 1;\n            width: 50%;\n            min-width: 50%;\n        }\n        .right-panel {\n            flex: 1;\n            width: 50%;\n            min-width: 50%;\n            border-left: 2px solid #444444;\n            padding-left: 20px;\n        }\n        .section-header {\n            background-color: #333333;\n            padding: 8px 12px;\n            border-radius: 5px;\n            margin: 15px 0 10px 0;\n            border-left: 3px solid #0DC4D9;\n        }\n        .main-header {\n            text-align: center;\n            padding: 20px;\n            background: linear-gradient(135deg, #2d2d2d 0%, #3d3d3d 100%);\n            border-radius: 8px;\n            margin-bottom: 20px;\n            border: 1px solid #444444;\n        }\n        .button-group {\n            display: flex;\n            gap: 10px;\n            margin: 15px 0;\n            flex-wrap: wrap;\n        }\n        .jupyter-widgets {\n            background-color: #1a1a1a !important;\n        }\n        </style>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='\\n            <div class=\"main-header\">\\n                <h1 style=\"color: #ffffff;…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cea375c633614f2695b7129a380aabb3"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# # Hindi Language Evaluation - CER & WER\n# import evaluate\n# from datasets import load_dataset\n# import pandas as pd\n# import numpy as np\n# import os\n\n# print(\"=== HINDI LANGUAGE EVALUATION ===\")\n\n# # Configuration\n# MODEL_DIR = \"./whisper_finetuned\"\n# BASE_MODEL = \"openai/whisper-medium\"\n# TEST_SPLIT = \"test\"\n# MAX_SAMPLES = 50\n# LANG_CODE = \"hi_in\"\n# LANG_NAME = \"Hindi\"\n\n# # Load metrics\n# wer_metric = evaluate.load(\"wer\")\n# cer_metric = evaluate.load(\"cer\")\n\n# # Load model\n# from transformers import WhisperForConditionalGeneration, WhisperProcessor\n# import torch\n\n# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# if os.path.exists(MODEL_DIR) and os.path.exists(os.path.join(MODEL_DIR, \"config.json\")):\n#     print(f\"Loading fine-tuned model from {MODEL_DIR}\")\n#     processor = WhisperProcessor.from_pretrained(MODEL_DIR)\n#     model = WhisperForConditionalGeneration.from_pretrained(MODEL_DIR).to(device)\n#     model_type = \"Fine-tuned\"\n# else:\n#     print(f\"Using base model: {BASE_MODEL}\")\n#     processor = WhisperProcessor.from_pretrained(BASE_MODEL)\n#     model = WhisperForConditionalGeneration.from_pretrained(BASE_MODEL).to(device)\n#     model_type = \"Base\"\n\n# print(f\"Model loaded: {model_type} Whisper Medium\")\n\n# # Load Hindi dataset\n# try:\n#     ds = load_dataset(\"google/fleurs\", LANG_CODE, split=TEST_SPLIT, trust_remote_code=True)\n#     if MAX_SAMPLES:\n#         ds = ds.select(range(min(len(ds), MAX_SAMPLES)))\n#     print(f\"Loaded {len(ds)} samples for {LANG_NAME}\")\n# except Exception as e:\n#     print(f\"Failed to load {LANG_NAME} dataset: {e}\")\n#     ds = None\n\n# if ds is not None:\n#     def map_to_pred(batch):\n#         inputs = processor(batch[\"audio\"][\"array\"],\n#                           sampling_rate=batch[\"audio\"][\"sampling_rate\"],\n#                           return_tensors=\"pt\")\n#         input_feat = inputs.input_features.to(device)\n        \n#         with torch.no_grad():\n#             pred_ids = model.generate(input_feat,\n#                                      max_length=448,\n#                                      num_beams=5,\n#                                      early_stopping=True)\n        \n#         batch[\"prediction\"] = processor.batch_decode(pred_ids, skip_special_tokens=True)[0]\n#         batch[\"reference\"] = batch[\"transcription\"]\n#         return batch\n    \n#     print(f\"Transcribing {LANG_NAME} test samples...\")\n#     pred_ds = ds.map(map_to_pred, remove_columns=ds.column_names, batched=False)\n    \n#     preds = pred_ds[\"prediction\"]\n#     refs = pred_ds[\"reference\"]\n    \n#     # Compute metrics\n#     wer_score = wer_metric.compute(predictions=preds, references=refs)\n#     cer_score = cer_metric.compute(predictions=preds, references=refs)\n    \n#     print(f\"\\n{LANG_NAME} Results:\")\n#     print(f\"Samples: {len(preds)}\")\n#     print(f\"WER: {wer_score:.4f}\")\n#     print(f\"CER: {cer_score:.4f}\")\n    \n#     # Show examples\n#     print(f\"\\n{LANG_NAME} Sample Predictions:\")\n#     examples_df = pd.DataFrame({\n#         \"Reference\": [ref[:60] + \"...\" if len(ref) > 60 else ref for ref in refs[:3]],\n#         \"Prediction\": [pred[:60] + \"...\" if len(pred) > 60 else pred for pred in preds[:3]]\n#     })\n#     print(examples_df.to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:56:20.759320Z","iopub.execute_input":"2025-07-14T07:56:20.759556Z","iopub.status.idle":"2025-07-14T07:56:59.293537Z","shell.execute_reply.started":"2025-07-14T07:56:20.759532Z","shell.execute_reply":"2025-07-14T07:56:59.292165Z"}},"outputs":[{"name":"stdout","text":"=== HINDI LANGUAGE EVALUATION ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcad493a2ec843c2ab09cc5e6b97ad69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02ddbb6c98664efbbe4740d7cbce83b1"}},"metadata":{}},{"name":"stdout","text":"Using base model: openai/whisper-medium\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43e7364fa876498cbc6db98e265ce8cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a81df58aff174b35b2426e87429cb953"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cee613e2a7245e9805dc5066b13cb39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af1d1c68d7d14460ba7069289c6542bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7d1b31db8564544ba7b9371f5d9f7b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83a289fefd5c4d98a11fd58f0e04211d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07d11bffad7341bfbb66865ebfdc77fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9f0278f829e4df3956a8e4319a1909f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"147166dab7ad47048cbd6c90b9b1e8f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.06G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7b8015a16d146e0b8e9f41238f93d96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cdd024074c7443895491bdad239964e"}},"metadata":{}},{"name":"stdout","text":"Model loaded: Base Whisper Medium\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2bc64fdd5df4d489b3c0782822e4a71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"fleurs.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4af4e6eb13624ac28ad5017885237734"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/hi_in/audio/train.tar.gz:   0%|          | 0.00/1.26G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e3e9135e4314b06b25f4fc3e175900f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/hi_in/audio/dev.tar.gz:   0%|          | 0.00/132M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e04fe9477cb41e9857250b3bc965e42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/hi_in/audio/test.tar.gz:   0%|          | 0.00/249M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"deb0e99f1a154f3cb63ba8fef42d9f9c"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1228647549.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Load Hindi dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"google/fleurs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLANG_CODE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEST_SPLIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mMAX_SAMPLES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_SAMPLES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m     \u001b[0;31m# Download and prepare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2084\u001b[0;31m     builder_instance.download_and_prepare(\n\u001b[0m\u001b[1;32m   2085\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m         \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                         \u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_proc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_proc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m                     self._download_and_prepare(\n\u001b[0m\u001b[1;32m    926\u001b[0m                         \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m                         \u001b[0mverification_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_download_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mprepare_splits_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m         super()._download_and_prepare(\n\u001b[0m\u001b[1;32m   1650\u001b[0m             \u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0msplit_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSplitDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0msplit_generators_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_split_generators_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m         \u001b[0msplit_generators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msplit_generators_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;31m# Checksums verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/huggingface/modules/datasets_modules/datasets/google--fleurs/80cb68d1b4d319aefbd8ea302274d3950d95f6242f0742c1452d1545c80a2d5f/fleurs.py\u001b[0m in \u001b[0;36m_split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0marchive_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mlocal_extracted_archives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_paths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_streaming\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0marchive_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marchive_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, path_or_paths)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_compressed_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mextract_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         extracted_paths = map_nested(\n\u001b[0m\u001b[1;32m    300\u001b[0m             \u001b[0mextract_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mpath_or_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0miterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         mapped = [\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhf_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0miterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         mapped = [\n\u001b[0;32m--> 522\u001b[0;31m             \u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhf_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         ]\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    407\u001b[0m             }\n\u001b[1;32m    408\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    407\u001b[0m             }\n\u001b[1;32m    408\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m     if (\n\u001b[1;32m    385\u001b[0m         \u001b[0mbatched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36m_download_single\u001b[0;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;31m# append the relative path to the base_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0murl_or_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl_or_path_join\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracked_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_origin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/utils/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;31m# Eager extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         output_path = ExtractManager(cache_dir=download_config.cache_dir).extract(\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_extract\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_extract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/utils/extract.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, input_path, force_extract)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_extract\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextractor_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/utils/extract.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(cls, input_path, output_path, extractor_format)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mextractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mextractor_format\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/utils/extract.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(input_path, output_path)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mtar_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mtar_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTarExtractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafemembers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mtar_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/tarfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, numeric_owner, filter)\u001b[0m\n\u001b[1;32m   2310\u001b[0m                 \u001b[0;31m# extracting contents can reset mtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m                 \u001b[0mdirectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfiltered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2312\u001b[0;31m             self._extract_one(tarinfo, path, set_attrs=not tarinfo.isdir(),\n\u001b[0m\u001b[1;32m   2313\u001b[0m                               \u001b[0mnumeric_owner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_owner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2314\u001b[0m                               filter_function=filter_function)\n","\u001b[0;32m/usr/lib/python3.11/tarfile.py\u001b[0m in \u001b[0;36m_extract_one\u001b[0;34m(self, tarinfo, path, set_attrs, numeric_owner, filter_function)\u001b[0m\n\u001b[1;32m   2413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2415\u001b[0;31m             self._extract_member(tarinfo, os.path.join(path, tarinfo.name),\n\u001b[0m\u001b[1;32m   2416\u001b[0m                                  \u001b[0mset_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_attrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m                                  \u001b[0mnumeric_owner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_owner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/tarfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, tarinfo, targetpath, set_attrs, numeric_owner, filter_function, extraction_root)\u001b[0m\n\u001b[1;32m   2502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misreg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2504\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2505\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/tarfile.py\u001b[0m in \u001b[0;36mmakefile\u001b[0;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[1;32m   2559\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2560\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2561\u001b[0;31m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmakeunknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/tarfile.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(src, dst, length, exception, bufsize)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected end of data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0muncompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":11},{"cell_type":"code","source":"# # English Language Evaluation - CER & WER\n# import evaluate\n# from datasets import load_dataset\n# import pandas as pd\n# import numpy as np\n\n# print(\"=== ENGLISH LANGUAGE EVALUATION ===\")\n\n# # Configuration\n# LANG_CODE = \"en_us\"\n# LANG_NAME = \"English\"\n\n# # Load English dataset\n# try:\n#     ds = load_dataset(\"google/fleurs\", LANG_CODE, split=TEST_SPLIT, trust_remote_code=True)\n#     if MAX_SAMPLES:\n#         ds = ds.select(range(min(len(ds), MAX_SAMPLES)))\n#     print(f\"Loaded {len(ds)} samples for {LANG_NAME}\")\n# except Exception as e:\n#     print(f\"Failed to load {LANG_NAME} dataset: {e}\")\n#     ds = None\n\n# if ds is not None:\n#     def map_to_pred(batch):\n#         inputs = processor(batch[\"audio\"][\"array\"],\n#                           sampling_rate=batch[\"audio\"][\"sampling_rate\"],\n#                           return_tensors=\"pt\")\n#         input_feat = inputs.input_features.to(device)\n        \n#         with torch.no_grad():\n#             pred_ids = model.generate(input_feat,\n#                                      max_length=448,\n#                                      num_beams=5,\n#                                      early_stopping=True)\n        \n#         batch[\"prediction\"] = processor.batch_decode(pred_ids, skip_special_tokens=True)[0]\n#         batch[\"reference\"] = batch[\"transcription\"]\n#         return batch\n    \n#     print(f\"Transcribing {LANG_NAME} test samples...\")\n#     pred_ds = ds.map(map_to_pred, remove_columns=ds.column_names, batched=False)\n    \n#     preds = pred_ds[\"prediction\"]\n#     refs = pred_ds[\"reference\"]\n    \n#     # Compute metrics\n#     wer_score = wer_metric.compute(predictions=preds, references=refs)\n#     cer_score = cer_metric.compute(predictions=preds, references=refs)\n    \n#     print(f\"\\n{LANG_NAME} Results:\")\n#     print(f\"Samples: {len(preds)}\")\n#     print(f\"WER: {wer_score:.4f}\")\n#     print(f\"CER: {cer_score:.4f}\")\n    \n#     # Show examples\n#     print(f\"\\n{LANG_NAME} Sample Predictions:\")\n#     examples_df = pd.DataFrame({\n#         \"Reference\": [ref[:60] + \"...\" if len(ref) > 60 else ref for ref in refs[:3]],\n#         \"Prediction\": [pred[:60] + \"...\" if len(pred) > 60 else pred for pred in preds[:3]]\n#     })\n#     print(examples_df.to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:56:59.294020Z","iopub.status.idle":"2025-07-14T07:56:59.294274Z","shell.execute_reply.started":"2025-07-14T07:56:59.294153Z","shell.execute_reply":"2025-07-14T07:56:59.294173Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Tamil Language Evaluation - CER & WER\n# import evaluate\n# from datasets import load_dataset\n# import pandas as pd\n# import numpy as np\n\n# print(\"=== TAMIL LANGUAGE EVALUATION ===\")\n\n# # Configuration\n# LANG_CODE = \"ta_in\"\n# LANG_NAME = \"Tamil\"\n\n# # Load Tamil dataset\n# try:\n#     ds = load_dataset(\"google/fleurs\", LANG_CODE, split=TEST_SPLIT, trust_remote_code=True)\n#     if MAX_SAMPLES:\n#         ds = ds.select(range(min(len(ds), MAX_SAMPLES)))\n#     print(f\"Loaded {len(ds)} samples for {LANG_NAME}\")\n# except Exception as e:\n#     print(f\"Failed to load {LANG_NAME} dataset: {e}\")\n#     ds = None\n\n# if ds is not None:\n#     def map_to_pred(batch):\n#         inputs = processor(batch[\"audio\"][\"array\"],\n#                           sampling_rate=batch[\"audio\"][\"sampling_rate\"],\n#                           return_tensors=\"pt\")\n#         input_feat = inputs.input_features.to(device)\n        \n#         with torch.no_grad():\n#             pred_ids = model.generate(input_feat,\n#                                      max_length=448,\n#                                      num_beams=5,\n#                                      early_stopping=True)\n        \n#         batch[\"prediction\"] = processor.batch_decode(pred_ids, skip_special_tokens=True)[0]\n#         batch[\"reference\"] = batch[\"transcription\"]\n#         return batch\n    \n#     print(f\"Transcribing {LANG_NAME} test samples...\")\n#     pred_ds = ds.map(map_to_pred, remove_columns=ds.column_names, batched=False)\n    \n#     preds = pred_ds[\"prediction\"]\n#     refs = pred_ds[\"reference\"]\n    \n#     # Compute metrics\n#     wer_score = wer_metric.compute(predictions=preds, references=refs)\n#     cer_score = cer_metric.compute(predictions=preds, references=refs)\n    \n#     print(f\"\\n{LANG_NAME} Results:\")\n#     print(f\"Samples: {len(preds)}\")\n#     print(f\"WER: {wer_score:.4f}\")\n#     print(f\"CER: {cer_score:.4f}\")\n    \n#     # Show examples\n#     print(f\"\\n{LANG_NAME} Sample Predictions:\")\n#     examples_df = pd.DataFrame({\n#         \"Reference\": [ref[:60] + \"...\" if len(ref) > 60 else ref for ref in refs[:3]],\n#         \"Prediction\": [pred[:60] + \"...\" if len(pred) > 60 else pred for pred in preds[:3]]\n#     })\n#     print(examples_df.to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:56:59.295515Z","iopub.status.idle":"2025-07-14T07:56:59.295849Z","shell.execute_reply.started":"2025-07-14T07:56:59.295680Z","shell.execute_reply":"2025-07-14T07:56:59.295695Z"}},"outputs":[],"execution_count":null}]}